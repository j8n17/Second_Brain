---
tags:
- token
- corpus
- instance
- N-gram
- Lemma
---

# Corpus 구성 요소

- Text - 문서.
- Token - 공백 또는 구두점으로 구분된 유의미한 단위.
- Metadata - 텍스트에 관련한 기타 정보, ex) label, 저장시간, 수정시간 등
- Instance - Metadata + Text.
- Corpus - 여러개의 Instance가 있는 dataset.

![[Pasted image 20230918130523.png|500]]

# Tokenize

Tokenization - 라이브러리를 사용해 text를 token으로 나눔

ex) spaCy, NLTK

spacy는 문장을 집어넣었을 때 한 단어씩 반환하는 iterator를 반환하고,
nltk는 문장을 집어넣었을 때 모든 단어를 나눠서 tuple로 반환한다.

# 교착어

교착어 (agglutinative languages) - 어근, 접사 등을 사용해 과학적으로 만들어진 언어, 이들의 전처리는 다른 언어들과 다름. 하지만 최근에는 언어에 상관없이 동일하게 전처리할 수 있는 방법이 등장.

![[Pasted image 20230918142016.png | 500]]
교착어 예시 - 터키어

# Types

Corpus(Dataset)에 있는 고유한 토큰.

ex) 트위터 Corpus에는 '#'을 사용한 해쉬태그, '@'를 사용한 멘션 등 고유한 토큰들이 있음.

# Words
단어는 Content words와 Stop words로 나뉨.

- Content words - 의미를 내포하는 단어.
- Stop words - 문법상 있는 단어로 크게 의미가 없는 단어. ex) The, a, an, ...

# N-gram
N개로 연속된 Token들.

ex) Unigrams, Bigrams, Trigrams, ...

# Subword
단어 내에 있는 의미를 내포한 특정 단어.

ex) 'methanol'에서의 'ol'은 subword로 알코올을 의미.

이런 subword가 많은 text에 대해서는 n-gram이 유용.

# Lemma
Lemmas and Stems - 어근

Lemmatization은 표제어 추출, Stemming은 어간 추출을 뜻한다.

어간 추출은 단어의 어미를 잘라 어근을 추출하고, 표제어 추출은 문법적인 요소와 의미를 감안해 어근을 추출한다. 그래서 Lemmatization이 더 잘된다.

이런 어근 추출을 통해 token의 수를 줄여 벡터 표현의 차원을 낮게 유지할 수 있다.

ex) flow, flew, flies, flown, flowing 등의 Lemma는 fly


# 2위 솔루션

## 팁
1. step by step - 맨 뒤에 step by step를 붙이면 단계별로 구성된 명확하고 체계적인 답변을 제공할 가능성이 높아진다. 특히 code를 요청할 때 질문자가 명확하게 이해할 수 있는 code를 받을 수 있다.
2. continue - 긴 글 작성시 중간에 멈추고 끝나는 경우가 있다. 이 때 continue라고 하면 이전 내용을 이어서 작성해준다.
3. I'm 8 years old - 질문자의 상황에 맞는 magic word를 붙이면 이해하기 쉬운 설명을 얻을 수 있다.
4. 최신 코드 - 최신 라이브러리의 documents를 입력해주면 이를 바탕으로 요구에 맞는 코드를 작성해준다.

## 프롬프트 전문 및 의도

1. 구체적이고 명확하게 요청
	1. 먼저 뭘 하고 싶은지 명시 - I want to train a model that classify the categories of news article.
	2. 처음으로 할 내용 명시 (데이터 split) - First, I need to split the data.
		1. 데이터 형식 명시 - data: 'train.csv'(id, text, label), 'test.csv'(id, text) num_label: 8
		2. text column이 뉴스 텍스트 - text column has news article data.
		3. 어떻게 데이터 전처리할 것인지 명시
			1. split - 1. I'll split the train data with stratified K-fold (K=5, random_state=1)
			2. 2. Use only first split. (train_df, val_df)
			3. 3. tokenize with roberta-base (max_len = 512)
	3. 모델 학습 - Second, I need to train the model.
		1. 어떤 모델 사용할 건지 - 1. Use roberta-base (max_len = 512)
		2. 옵티마이저 명시 - Use AdamW optimizer
		3. 배치사이즈, 에폭 명시 - batch size 8, epoch 10
		4. 검증 방법 명시 - eval metric for validation is the macro f1 score.
		5. 모델 저장 명시 - save the best .pt file
		6. 결과 저장 명시 - save a inference file (id, label)
	4. 단계별로 차근차근 작성 명시 - write full code. step by step

==코드 사용환경에 대한 내용도 명시하면 좋을 것 같음.==

==(궁금한 점) - 온점을 안찍는 경우, 대문자 사용안하는 경우 성능에 영향을 미칠까?==
==대화가 길어지면 길어질수록 이전 내용에 대해서 기억을 못할까?== ==만약 그렇다면 여러 세션에서 사용하는 것이 더 나을까?==

2. 에러 메세지 전문 입력 - 맨앞에 에러가 발생한 코드 입력, 중간에 에러메세지, 맨 뒤에 this error in your code.
3. 에러 메세지 전문 입력 - 에러 메세지 입력, 중간에 this error in your code., 맨 뒤에 에러 코드 입력
4. 에폭이 올라도 트레이닝이 안되는 이유 질문 - 코드 전문 입력 후 this code, the macro f1 score doesn't increase while epoch increase. I don't know why.
5. 코드에 lr 관련 코드 추가 요청 - 코드 전문 입력 후 how can i set learning rate in this code?
6. 데이터 증강 코드 요청 - 데이터 불균형을 보여주는 표 입력, I want to do text augmentation for label 6, 7 of train_df. train_df has 'text' column. And save a 'aug.csv'. file for augmented data. Number of augmented samples per original sample : 5. And update train_df.
7. 중간중간 에러 및 모델 크기 조정
8. 전처리 함수 요청 (명확하고 구체적이고 체계적으로) - HTML를 unicode로 바꾸거나 http, https 등을 제거하거나, 이메일 제거, 트위터 아이디 제거 등등

10. 중간에 처음과는 여러부분 추가됐지만 처음 질문했던 것 처럼 구체적으로 요청(헷갈리지 않도록) - preprocess with def preprocess_text(text), Use AdamW optimizer, learning rate = 1e-5, Use weighted loss function (cross-entropy loss), evaluate training dataset and val dataset, print classification_report and macro f1 score. 코드 추가 (classification_report 코드는 이전에 말한 적이 없기 때문인지 추가가 안되었음.)

아마 여기서 2위팀 솔루션 pdf가 섞인듯.
11. Loss function 수정 요청 - Modify your code to use Label Smoothing Loss rather than CrossEntrophy Loss.
12. hyper parameter 수정 요청 - Modify smoothing 0.01
13. train에서 loss 계산하는 부분 코드 수정 - train loop 부분 코드 입력후 modify this part as well

14. 코드 전문 입력후 augment data 추가 요청 - I have this code. I have 'sum_aug.csv', 'backtrans_aug.csv'(id, text, label) between step4 and step5, write a code to add the augmented data for same id with train_df id.
15. before concat, you sould check if the id between train_df and augmented data.
16. i have this code. I have 'sum_aub.csv', 'backtrans_aub.csv'(id, text, label). between step4 and step5, write a code to add the augmented data for same id with train_df id. 1. load sum_aug.csv and backtrans_aug.csv. 2. filter them by train_df['id']. just extract specific rows. 3. append rows under the train_df
17. val data에도 aug data를 추가해서 이 부분 수정 - no extended data for val_data.
18. augment로 추가한 후 preprocessing 하도록 순서 변경 - write the code to preprocess them after this. ==(them이라고 하는 것보다 data라고 하는 것이 더 명확해보인다.)==
19. extended_train_df를 train_df로 변경할 때 일부분만 변경하지 말고 전부다 변경 - not some of it. all of it.
20. batch size 조정 요청 - dataloader 코드 입력 후 modify the code to batch_size 32



==만약 전처리에 관련된 코드 수정이 완료되었으면 전처리 코드는 완벽하다고 명시해주면 기억하기에도 좋을 것 같다.==




19. classification_report 추가 요청 - add the code to print classification_report
20. (잘못된 코드 위치 조정) 한 에폭이 끝난 후 classification_report를 해서 다시 요청 - print(classification_report(val_true, val_preds)) this is the code for classification_report? : ==다행히 gpt가 잘 알아들었지만 위치가 잘못되었다고 더 명확히 알려줬으면 어땠을까?==
21. 코드에서 next()를 사용하는 부분을 리스트의 인덱스로 변경 - can i just index it, rather than next?
22. fold에 맞는 모델 파일명 - best_model_path = 'best_model.pt'. I want variable to be best_model{fold_num}.pt
23. fold 인덱스로 지정 - train_idx, val_idx = folds[0]. want to use fold_num's indices.
24. submission.to_csv('inference.csv', index=False). I want file name like inference_{fold_num}
25. ensemble 코드 요청 - I have 5 'inference.csv'(id, text) files. I want to improve my model performance. write the python code to do hard voting for ensemble.
26. ensemble 코드에서 0부터 4중에 1, 3만 사용 - 앙상블 코드 입력 후 modify this code. not use inference. 0 to 4. just use 1, 3.


1. back translation을 통해 data aug - I have 'train.csv'(id, text, label). I want to do data augmentation by using back translation. text column has news article data. write the code for back translation.
2. 모델 변경 요청 - can you modify the code with t5-base model?
3. 토크나이저 변경 - Use AutoTokenizer, AutoModelForSeq2SeqLM with 't5-base'.


1. train_augmented.csv 파일에 rows들을 append하기 위한 요청 - add the code to check condition if the train_augmented.csv file exists before trying to read it. If the file does not exist, you can create an empty DataFrame with the same columns. and if it exists, append the rows.
   ==Add the code to check whether the train_augmented.csv file exists or not before trying to read it. 라고 하면 어땠을까?==
   ==GPT가 추천한 문장 : Add code to verify the existence of 'train_augmented.csv' before attempting to read it. -> 조금 더 간결하고 명확해서 기술적인 부분에서 더 유용하다.==


1. 최종 inference code - I have this code. Remove all the code for training. Just remain for inference. ==차라리 이렇게 하는 것보다 training에 대한 코드 먼저 만들고 나중에 inference code를 만들면 어땠을까?==

==전처리 함수를 만들기 전에 EDA를 할 수 있는 코드를 먼저 요청해서 데이터를 분석했다면 어땠을까?==
==특이한 데이터를 찾을 수 있는 방법을 추천받았다면?==

==ChatGPT에게 어떻게 요청하는게 좋을지 물어보는 세션을 만들면 좋을 것 같다. 예를 들어 이 코드에 augmented data를 추가할건데 어떻게 요청하는게 좋을지 물어보기==

==논문 방향으로 하면 좋을 것
ChatGPT를 통해 현재 우리가 할 수 있는 것들을 대신 할 수 있게 하는 것, ChatGPT를 통해 우리가 생각하지 못한 부분을 알려줄 수 있게 하는 것==

## 현재 ChatGPT가 가진 장단점

### 단점



# 프롬프트 엔지니어링 논문 작성시 생각해야할 것

제한 사항을 어떻게 설정할 것인지 생각. 예를 들어 인터넷 접속은 허용할 것인지? 아니면 플러그인들을 사용할 것인지 등.. 관련 논문을 참고해야 할듯